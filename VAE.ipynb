{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Description: VAE\n",
    "@Author: Dezhan Tu\n",
    "@LastEditTime: 08/23/2020\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data utility\n",
    "\n",
    "# Convert data to torch.FloatTensor\n",
    "img_transform  = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download MNIST Dataset\n",
    "train_dataset = MNIST(\n",
    "    root=\"./dataset\", \n",
    "    train=True, \n",
    "    transform=img_transform, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root=\"./dataset\", \n",
    "    train=False, \n",
    "    transform=img_transform, \n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def save_epoch_img(img, epoch):\n",
    "    \"\"\"\n",
    "    save img during training process\n",
    "    \"\"\"\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, './VAE_Result/VAE_{}.png'.format(epoch))\n",
    "\n",
    "\n",
    "def make_dir():\n",
    "    \"\"\"\n",
    "    make directory to store result\n",
    "    \"\"\"\n",
    "    if not os.path.exists('VAE_Result'):\n",
    "        os.makedirs('VAE_Result')\n",
    "        \n",
    "make_dir()    #Create result directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    class for variational autoencoder(VAE)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        init VAE network structure\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc21 = nn.Linear(256, 32)   #mean\n",
    "        self.fc22 = nn.Linear(256, 32)   #variance\n",
    "        self.fc3 = nn.Linear(32, 256)\n",
    "        self.fc4 = nn.Linear(256, 784)     \n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        encoding process\n",
    "        \"\"\"\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        generate latent vector randomly\n",
    "        \"\"\"\n",
    "        std = torch.exp(log_var * 0.5)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        decoding process\n",
    "        \"\"\"\n",
    "        h3 = torch.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x = self.decode(z)\n",
    "        return x, mu, log_var\n",
    "    \n",
    "# Reconstruction + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    \n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/100, Training loss = 22682.541\n",
      "Epoch : 2/100, Training loss = 16648.973\n",
      "Epoch : 3/100, Training loss = 15372.358\n",
      "Epoch : 4/100, Training loss = 14789.311\n",
      "Epoch : 5/100, Training loss = 14455.871\n",
      "Epoch : 6/100, Training loss = 14246.921\n",
      "Epoch : 7/100, Training loss = 14091.546\n",
      "Epoch : 8/100, Training loss = 13980.863\n",
      "Epoch : 9/100, Training loss = 13891.288\n",
      "Epoch : 10/100, Training loss = 13822.959\n",
      "Epoch : 11/100, Training loss = 13758.233\n",
      "Epoch : 12/100, Training loss = 13715.204\n",
      "Epoch : 13/100, Training loss = 13676.213\n",
      "Epoch : 14/100, Training loss = 13636.315\n",
      "Epoch : 15/100, Training loss = 13606.857\n",
      "Epoch : 16/100, Training loss = 13582.937\n",
      "Epoch : 17/100, Training loss = 13560.845\n",
      "Epoch : 18/100, Training loss = 13533.290\n",
      "Epoch : 19/100, Training loss = 13523.884\n",
      "Epoch : 20/100, Training loss = 13498.326\n",
      "Epoch : 21/100, Training loss = 13485.002\n",
      "Epoch : 22/100, Training loss = 13463.412\n",
      "Epoch : 23/100, Training loss = 13453.164\n",
      "Epoch : 24/100, Training loss = 13445.775\n",
      "Epoch : 25/100, Training loss = 13426.509\n",
      "Epoch : 26/100, Training loss = 13414.071\n",
      "Epoch : 27/100, Training loss = 13403.878\n",
      "Epoch : 28/100, Training loss = 13391.418\n",
      "Epoch : 29/100, Training loss = 13382.680\n",
      "Epoch : 30/100, Training loss = 13376.910\n",
      "Epoch : 31/100, Training loss = 13370.088\n",
      "Epoch : 32/100, Training loss = 13354.131\n",
      "Epoch : 33/100, Training loss = 13346.439\n",
      "Epoch : 34/100, Training loss = 13340.747\n",
      "Epoch : 35/100, Training loss = 13331.344\n",
      "Epoch : 36/100, Training loss = 13323.867\n",
      "Epoch : 37/100, Training loss = 13317.419\n",
      "Epoch : 38/100, Training loss = 13310.786\n",
      "Epoch : 39/100, Training loss = 13304.091\n",
      "Epoch : 40/100, Training loss = 13301.960\n",
      "Epoch : 41/100, Training loss = 13289.758\n",
      "Epoch : 42/100, Training loss = 13284.446\n",
      "Epoch : 43/100, Training loss = 13272.549\n",
      "Epoch : 44/100, Training loss = 13273.875\n",
      "Epoch : 45/100, Training loss = 13267.783\n",
      "Epoch : 46/100, Training loss = 13259.879\n",
      "Epoch : 47/100, Training loss = 13253.643\n",
      "Epoch : 48/100, Training loss = 13248.107\n",
      "Epoch : 49/100, Training loss = 13243.192\n",
      "Epoch : 50/100, Training loss = 13241.673\n",
      "Epoch : 51/100, Training loss = 13242.086\n",
      "Epoch : 52/100, Training loss = 13233.225\n",
      "Epoch : 53/100, Training loss = 13226.625\n",
      "Epoch : 54/100, Training loss = 13219.291\n",
      "Epoch : 55/100, Training loss = 13216.291\n",
      "Epoch : 56/100, Training loss = 13215.230\n",
      "Epoch : 57/100, Training loss = 13209.452\n",
      "Epoch : 58/100, Training loss = 13211.057\n",
      "Epoch : 59/100, Training loss = 13202.749\n",
      "Epoch : 60/100, Training loss = 13199.285\n",
      "Epoch : 61/100, Training loss = 13197.590\n",
      "Epoch : 62/100, Training loss = 13191.358\n",
      "Epoch : 63/100, Training loss = 13183.537\n",
      "Epoch : 64/100, Training loss = 13180.495\n",
      "Epoch : 65/100, Training loss = 13179.968\n",
      "Epoch : 66/100, Training loss = 13179.860\n",
      "Epoch : 67/100, Training loss = 13167.284\n",
      "Epoch : 68/100, Training loss = 13173.138\n",
      "Epoch : 69/100, Training loss = 13161.972\n",
      "Epoch : 70/100, Training loss = 13166.262\n",
      "Epoch : 71/100, Training loss = 13165.375\n",
      "Epoch : 72/100, Training loss = 13156.976\n",
      "Epoch : 73/100, Training loss = 13151.184\n",
      "Epoch : 74/100, Training loss = 13148.475\n",
      "Epoch : 75/100, Training loss = 13150.525\n",
      "Epoch : 76/100, Training loss = 13143.917\n",
      "Epoch : 77/100, Training loss = 13142.842\n",
      "Epoch : 78/100, Training loss = 13135.024\n",
      "Epoch : 79/100, Training loss = 13138.454\n",
      "Epoch : 80/100, Training loss = 13138.837\n",
      "Epoch : 81/100, Training loss = 13132.011\n",
      "Epoch : 82/100, Training loss = 13125.358\n",
      "Epoch : 83/100, Training loss = 13125.686\n",
      "Epoch : 84/100, Training loss = 13128.937\n",
      "Epoch : 85/100, Training loss = 13118.183\n",
      "Epoch : 86/100, Training loss = 13116.918\n",
      "Epoch : 87/100, Training loss = 13112.675\n",
      "Epoch : 88/100, Training loss = 13111.131\n",
      "Epoch : 89/100, Training loss = 13108.825\n",
      "Epoch : 90/100, Training loss = 13108.895\n",
      "Epoch : 91/100, Training loss = 13106.377\n",
      "Epoch : 92/100, Training loss = 13103.763\n",
      "Epoch : 93/100, Training loss = 13100.551\n",
      "Epoch : 94/100, Training loss = 13095.584\n",
      "Epoch : 95/100, Training loss = 13095.709\n",
      "Epoch : 96/100, Training loss = 13095.887\n",
      "Epoch : 97/100, Training loss = 13091.519\n",
      "Epoch : 98/100, Training loss = 13086.055\n",
      "Epoch : 99/100, Training loss = 13084.367\n",
      "Epoch : 100/100, Training loss = 13085.848\n"
     ]
    }
   ],
   "source": [
    "# Use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate an VAE\n",
    "model = VAE().to(device)\n",
    "\n",
    "# Mean-Squared Error Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training Process\n",
    "loss_output = []\n",
    "loss = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for img, _ in train_loader:\n",
    "        img = img.view(-1, 784).to(device)    # Reshape mini-batch data\n",
    "        optimizer.zero_grad()                 # Reset the gradients back to zero\n",
    "        recon_batch, mu, logvar = model(img)  # Reconstruction\n",
    "        train_loss = loss_function(recon_batch, img, mu, logvar)   # Reconstruction + KL divergence losses\n",
    "        train_loss.backward()                 # Compute accumulated gradients\n",
    "        optimizer.step()                      # Parameters update\n",
    "        loss += train_loss.item()             # Add the mini-batch training loss to epoch loss\n",
    "\n",
    "        \n",
    "    loss = loss / len(train_loader)           # Compute the epoch training loss\n",
    "    loss_output.append(loss)    \n",
    "\n",
    "            \n",
    "    # Display the training loss\n",
    "    print(\"Epoch : {}/{}, Training loss = {:.3f}\".format(epoch + 1, NUM_EPOCHS, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img,_ in test_loader:\n",
    "    img = img.view(-1, 784).to(device)    # Reshape mini-batch data\n",
    "    recon_batch, _, _ = model(img)  # Testing phase \n",
    "    recon_batch = recon_batch.view(recon_batch.size(0), 1, 28, 28).cpu().data\n",
    "    i = i + 1\n",
    "    save_image(recon_batch.cpu(), 'VAE_Result/reconstruction_{}.png'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
